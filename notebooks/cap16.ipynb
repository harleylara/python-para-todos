{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/cover-small.jpg\">\n",
    "\n",
    "*Este libro es una versión al español de [Python for Everybody](https://www.py4e.com/) escrito por el [Dr. Charles R. Severance](http://www.dr-chuck.com/); este contenido esta disponible en [GitHub](https://github.com/csev/py4e).*\n",
    "\n",
    "Detalles de Copyright\n",
    "\n",
    "*Copyright ~ 2009- Charles Severance.\n",
    "Este trabajo está registrado bajo una Licencia Creative Commons AttributionNonCommercial-ShareAlike 3.0 [CC BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/3.0/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "| [Indice](indice.ipynb) | \n",
    "\n",
    "< [Capítulo 15 - Uso de bases de datos y SQL](cap15.ipynb) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 16 - Visualización de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos estado aprendiendo el lenguaje Python y luego aprendiendo cómo usar Python, la red y las bases de datos para manipular datos.\n",
    "\n",
    "En este capítulo, analizamos tres aplicaciones completas que reúnen todas estas cosas para administrar y visualizar datos. Puede usar estas aplicaciones como código de muestra para ayudarlo a comenzar a resolver un problema del mundo real.\n",
    "\n",
    "Cada una de las aplicaciones es un archivo ZIP que puede descargar y extraer en su computadora y ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un mapa de Google a partir de datos geocodificados\n",
    "\n",
    "En este proyecto, estamos utilizando la API de geocodificación de Google para limpiar algunas ubicaciones geográficas ingresadas por los usuarios de los nombres de las universidades y luego colocar los datos en un mapa de Google.\n",
    "\n",
    "![Figura 16.1](./figures/google-map.png)\n",
    "<center><i>Figura 16.1: Mapa de Google.</i></center>\n",
    "\n",
    "Para comenzar, descargue la aplicación desde: www.py4e.com/code3/geodata.zip\n",
    "\n",
    "El primer problema a resolver es que la API gratuita de geocodificación de Google está limitada a una determinada cantidad de solicitudes por día. Si tiene muchos datos, es posible que deba detener y reiniciar el proceso de búsqueda varias veces. Entonces dividimos el problema en dos fases.\n",
    "\n",
    "En la primera fase tomamos nuestros datos de \"encuesta\" de entrada en el archivo `where.data` y lo leemos una línea a la vez, y recuperamos la información geocodificada de Google y la almacenamos en una base de datos `geodata.sqlite`. Antes de usar la API de geocodificación para cada ubicación ingresada por el usuario, simplemente verificamos si ya tenemos los datos para esa línea de entrada en particular. La base de datos funciona como un \"caché\" local de nuestros datos de geocodificación para garantizar que nunca le solicitemos a Google los mismos datos dos veces.\n",
    "\n",
    "Puede reiniciar el proceso en cualquier momento eliminando el archivo `geodata.sqlite`.\n",
    "\n",
    "Ejecute el programa `geoload.py`. Este programa leerá las líneas de entrada en `where.data` y para cada línea verifique si ya está en la base de datos. Si no tenemos los datos para la ubicación, llamará a la API de geocodificación para recuperar los datos y almacenarlos en la base de datos.\n",
    "\n",
    "Aquí hay una muestra de ejecución después de que ya hay algunos datos en la base de datos:\n",
    "\n",
    "    Found in database  Northeastern University\n",
    "    Found in database  University of Hong Kong, ...\n",
    "    Found in database  Technion\n",
    "    Found in database  Viswakarma Institute, Pune, India\n",
    "    Found in database  UMD\n",
    "    Found in database  Tufts University\n",
    "\n",
    "    Resolving Monash University\n",
    "    Retrieving http://maps.googleapis.com/maps/api/\n",
    "        geocode/json?address=Monash+University\n",
    "    Retrieved 2063 characters {    \"results\" : [\n",
    "    {'status': 'OK', 'results': ... }\n",
    "\n",
    "    Resolving Kokshetau Institute of Economics and Management\n",
    "    Retrieving http://maps.googleapis.com/maps/api/\n",
    "        geocode/json?address=Kokshetau+Inst ...\n",
    "    Retrieved 1749 characters {    \"results\" : [\n",
    "    {'status': 'OK', 'results': ... }\n",
    "    ...\n",
    "\n",
    "Las primeras cinco ubicaciones ya están en la base de datos y, por lo tanto, se omiten. El programa escanea hasta el punto donde encuentra nuevas ubicaciones y comienza a recuperarlas.\n",
    "\n",
    "El programa `geoload.py` se puede detener en cualquier momento, y hay un contador que puede usar para limitar la cantidad de llamadas a la API de geocodificación para cada ejecución. Dado que `where.data` solo tiene unos pocos cientos de elementos de datos, no debe ejecutar el límite de velocidad diario, pero si tuviera más datos, podría tomar varias ejecuciones durante varios días para que su base de datos tenga todos los datos geocodificados para tu aportación.\n",
    "\n",
    "Una vez que tenga algunos datos cargados en `geodata.sqlite`, puede visualizar los datos usando el programa `geodump.py`. Este programa lee la base de datos y escribe el archivo `where.js` con la ubicación, latitud y longitud en forma de código JavaScript ejecutable.\n",
    "\n",
    "Una ejecución del programa `geodump.py` es la siguiente:\n",
    "\n",
    "    Northeastern University, ... Boston, MA 02115, USA 42.3396998 -71.08975\n",
    "    Bradley University, 1501 ... Peoria, IL 61625, USA 40.6963857 -89.6160811\n",
    "    ...\n",
    "    Technion, Viazman 87, Kesalsaba, 32000, Israel 32.7775 35.0216667\n",
    "    Monash University Clayton ... VIC 3800, Australia -37.9152113 145.134682\n",
    "    Kokshetau, Kazakhstan 53.2833333 69.3833333\n",
    "    ...\n",
    "    12 records written to where.js\n",
    "    Open where.html to view the data in a browser\n",
    "\n",
    "El archivo `where.html` consta de HTML y JavaScript para visualizar un mapa de Google. Lee los datos más recientes en `where.js` para obtener los datos que se visualizarán. Aquí está el formato del archivo `where.js`:\n",
    "\n",
    "    myData = [\n",
    "    [42.3396998,-71.08975, 'Northeastern Uni ... Boston, MA 02115'],\n",
    "    [40.6963857,-89.6160811, 'Bradley University, ... Peoria, IL 61625, USA'],\n",
    "    [32.7775,35.0216667, 'Technion, Viazman 87, Kesalsaba, 32000, Israel'],\n",
    "       ...\n",
    "    ];\n",
    "\n",
    "Esta es una variable de JavaScript que contiene una lista de listas. La sintaxis para las constantes de la lista de JavaScript es muy similar a Python, por lo que la sintaxis debería serle familiar.\n",
    "\n",
    "Simplemente abra `where.html` en un navegador para ver las ubicaciones. Puede pasar el cursor sobre cada pin del mapa para encontrar la ubicación que la API de geocodificación devolvió para la entrada ingresada por el usuario. Si no puede ver ningún dato al abrir el archivo `where.html`, puede consultar el JavaScript o la consola del desarrollador de su navegador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de redes e interconexiones\n",
    "\n",
    "En esta aplicación, realizaremos algunas de las funciones de un motor de búsqueda. Primero analizaremos un pequeño subconjunto de la web y ejecutaremos una versión simplificada del algoritmo de clasificación de páginas de Google para determinar qué páginas están más conectadas, y luego visualizaremos la clasificación de páginas y la conectividad de nuestro pequeño rincón de la web. Utilizaremos la biblioteca de visualización D3 JavaScript http://d3js.org/ para producir la salida de visualización.\n",
    "\n",
    "Puede descargar y extraer esta aplicación desde: www.py4e.com/code3/pagerank.zip.\n",
    "\n",
    "![Figura 16.2](./figures/pagerank.png)\n",
    "<center><i>Figura 16.2: Un ranking de una página.</i></center>\n",
    "\n",
    "El primer programa `spider.py` rastrea un sitio web y extrae una serie de páginas a la base de datos `spider.sqlite`, registrando los enlaces entre las páginas. Puede reiniciar el proceso en cualquier momento eliminando el archivo `spider.sqlite` y volviendo a ejecutar `spider.py`.\n",
    "\n",
    "    Enter web url or enter: http://www.dr-chuck.com/\n",
    "    ['http://www.dr-chuck.com']\n",
    "    How many pages:2\n",
    "    1 http://www.dr-chuck.com/ 12\n",
    "    2 http://www.dr-chuck.com/csev-blog/ 57\n",
    "    How many pages\n",
    "\n",
    "En este ejemplo, le dijimos que rastreara un sitio web y recuperara dos páginas. Si reinicia el programa y le dice que rastree más páginas, no volverá a rastrear ninguna página que ya esté en la base de datos. Al reiniciar, va a una página aleatoria no rastreada y comienza allí. Por lo tanto, cada ejecución sucesiva de `spider.py` es aditiva.\n",
    "\n",
    "    Enter web url or enter: http://www.dr-chuck.com/\n",
    "    ['http://www.dr-chuck.com']\n",
    "    How many pages:3\n",
    "    3 http://www.dr-chuck.com/csev-blog 57\n",
    "    4 http://www.dr-chuck.com/dr-chuck/resume/speaking.htm 1\n",
    "    5 http://www.dr-chuck.com/dr-chuck/resume/index.htm 13\n",
    "    How many pages:\n",
    "\n",
    "Puede tener múltiples puntos de partida en la misma base de datos; dentro del programa, estos se denominan \"webs\". La araña elige aleatoriamente entre todos los enlaces no visitados en todas las webs como la página siguiente a la araña.\n",
    "\n",
    "Si desea volcar el contenido del archivo `spider.sqlite`, puede ejecutar `spdump.py` de la siguiente manera:\n",
    "\n",
    "    (5, None, 1.0, 3, 'http://www.dr-chuck.com/csev-blog')\n",
    "    (3, None, 1.0, 4, 'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')\n",
    "    (1, None, 1.0, 2, 'http://www.dr-chuck.com/csev-blog/')\n",
    "    (1, None, 1.0, 5, 'http://www.dr-chuck.com/dr-chuck/resume/index.htm')\n",
    "    4 rows.\n",
    "\n",
    "Esto muestra el número de enlaces entrantes, el rango de página anterior, el nuevo rango de página, la identificación de la página y la URL de la página. El programa `spdump.py` solo muestra páginas que tienen al menos un enlace entrante.\n",
    "\n",
    "Una vez que tenga algunas páginas en la base de datos, puede ejecutar el rango de página en las páginas usando el programa `sprank.py`. Simplemente dígale cuántas iteraciones de rango de página ejecutar.\n",
    "\n",
    "    How many iterations:2\n",
    "    1 0.546848992536\n",
    "    2 0.226714939664\n",
    "    [(1, 0.559), (2, 0.659), (3, 0.985), (4, 2.135), (5, 0.659)]\n",
    "\n",
    "Puede volcar la base de datos nuevamente para ver que el rango de página se ha actualizado:\n",
    "\n",
    "    (5, 1.0, 0.985, 3, 'http://www.dr-chuck.com/csev-blog')\n",
    "    (3, 1.0, 2.135, 4, 'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')\n",
    "    (1, 1.0, 0.659, 2, 'http://www.dr-chuck.com/csev-blog/')\n",
    "    (1, 1.0, 0.659, 5, 'http://www.dr-chuck.com/dr-chuck/resume/index.htm')\n",
    "    4 rows.\n",
    "    \n",
    "Puede ejecutar `sprank.py` tantas veces como desee y simplemente refinará el rango de página cada vez que lo ejecute. Incluso puede ejecutar `sprank.py` varias veces y luego ir a spider algunas páginas más con `spider.py` y luego ejecutar `sprank.py` para volver a converger los valores de rango de página. Un motor de búsqueda generalmente ejecuta los programas de rastreo y clasificación todo el tiempo.\n",
    "\n",
    "Si desea reiniciar los cálculos de rango de página sin desplazar las páginas web, puede usar `spreset.py` y luego reiniciar `sprank.py`.\n",
    "\n",
    "    How many iterations:50\n",
    "    1 0.546848992536\n",
    "    2 0.226714939664\n",
    "    3 0.0659516187242\n",
    "    4 0.0244199333\n",
    "    5 0.0102096489546\n",
    "    6 0.00610244329379\n",
    "    ...\n",
    "    42 0.000109076928206\n",
    "    43 9.91987599002e-05\n",
    "    44 9.02151706798e-05\n",
    "    45 8.20451504471e-05\n",
    "    46 7.46150183837e-05\n",
    "    47 6.7857770908e-05\n",
    "    48 6.17124694224e-05\n",
    "    49 5.61236959327e-05\n",
    "    50 5.10410499467e-05\n",
    "    [(512, 0.0296), (1, 12.79), (2, 28.93), (3, 6.808), (4, 13.46)]\n",
    "\n",
    "Para cada iteración del algoritmo de rango de página, imprime el cambio promedio en el rango de página por página. Inicialmente, la red está bastante desequilibrada y, por lo tanto, los valores individuales de rango de página cambian enormemente entre iteraciones. Pero en algunas iteraciones cortas, el rango de la página converge. Debe ejecutar `sprank.py` el tiempo suficiente para que converjan los valores de rango de página.\n",
    "\n",
    "Si desea visualizar las páginas principales actuales en términos de rango de página, ejecute `spjson.py` para leer la base de datos y escriba los datos de las páginas más vinculadas en formato JSON para verlas en un navegador web.\n",
    "\n",
    "    Creating JSON output on spider.json...\n",
    "    How many nodes? 30\n",
    "    Open force.html in a browser to view the visualization\n",
    "\n",
    "Puede ver estos datos abriendo el archivo `force.html` en su navegador web. Esto muestra un diseño automático de los nodos y enlaces. Puede hacer clic y arrastrar cualquier nodo y también puede hacer doble clic en un nodo para encontrar la URL que está representada por el nodo.\n",
    "\n",
    "Si vuelve a ejecutar las otras utilidades, vuelva a ejecutar `spjson.py` y presione actualizar en el navegador para obtener los nuevos datos de `spider.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar datos de correo\n",
    "\n",
    "Hasta este punto en el libro, te has familiarizado bastante con nuestros archivos de datos `mbox-short.txt` y `mbox.txt`. Ahora es el momento de llevar nuestro análisis de datos de correo electrónico al siguiente nivel.\n",
    "\n",
    "En el mundo real, a veces hay que extraer los datos de correo de los servidores. Eso podría llevar bastante tiempo y los datos podrían ser inconsistentes, estar llenos de errores y necesitar mucha limpieza o ajuste. En esta sección, trabajamos con una aplicación que es la más compleja hasta ahora y extraemos casi un gigabyte de datos y los visualizamos.\n",
    "\n",
    "![Figura 16.3](./figures/wordcloud.png)\n",
    "<center><i>Figura 16.3: Una nube de palabras de la lista de desarrolladores de Sakai</i></center>\n",
    "\n",
    "Puede descargar esta aplicación desde: www.py4e.com/code3/gmane.zip.\n",
    "\n",
    "Utilizaremos datos de un servicio gratuito de archivo de listas de correo electrónico llamado www.gmane.org . Este servicio es muy popular entre los proyectos de código abierto porque proporciona un buen archivo de búsqueda de su actividad de correo electrónico. También tienen una política muy liberal con respecto al acceso a sus datos a través de su API. No tienen límites de velocidad, pero solicite que no sobrecargue su servicio y tome solo los datos que necesita. Puede leer los términos y condiciones de gmane en esta página: http://gmane.org/export.php.\n",
    "\n",
    "Es muy importante que haga uso responsable de los datos de gmane.org agregando demoras a su acceso a sus servicios y extendiendo los trabajos de larga duración durante un período de tiempo más largo. No abuse de este servicio gratuito y lo arruine para el resto de nosotros.\n",
    "\n",
    "Cuando los datos de correo electrónico de Sakai se procesaron utilizando este software, produjeron casi un Gigabyte de datos y tomaron varias ejecuciones en varios días. El archivo `README.txt` en el ZIP anterior puede tener instrucciones sobre cómo puede descargar una copia previamente dividida del archivo `content.sqlite` para la mayoría del corpus de correo electrónico de Sakai para que no tenga que arañar durante cinco días solo para ejecutar los programas Si descarga el contenido pre-spidered, aún debe ejecutar el proceso de spidering para ponerse al día con los mensajes más recientes.\n",
    "\n",
    "El primer paso es arañar el repositorio gmane. La URL base está codificada en `gmane.py` y está codificada en la lista de desarrolladores de Sakai. Puede arañar otro repositorio cambiando esa url base. Asegúrese de eliminar el archivo `content.sqlite` si cambia la url base.\n",
    "\n",
    "El archivo `gmane.py` funciona como una araña de almacenamiento en caché responsable, ya que se ejecuta lentamente y recupera un mensaje de correo por segundo para evitar ser estrangulado por gmane. Almacena todos sus datos en una base de datos y se puede interrumpir y reiniciar tantas veces como sea necesario. Puede llevar muchas horas extraer todos los datos. Por lo tanto, es posible que deba reiniciar varias veces.\n",
    "\n",
    "Aquí hay una ejecución de `gmane.py` recuperando los últimos cinco mensajes de la lista de desarrolladores de Sakai:\n",
    "\n",
    "    How many messages:10\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51410/51411 9460\n",
    "        nealcaidin@sakaifoundation.org 2013-04-05 re: [building ...\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51411/51412 3379\n",
    "        samuelgutierrezjimenez@gmail.com 2013-04-06 re: [building ...\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51412/51413 9903\n",
    "        da1@vt.edu 2013-04-05 [building sakai] melete 2.9 oracle ...\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51413/51414 349265\n",
    "        m.shedid@elraed-it.com 2013-04-07 [building sakai] ...\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51414/51415 3481\n",
    "        samuelgutierrezjimenez@gmail.com 2013-04-07 re: ...\n",
    "    http://download.gmane.org/gmane.comp.cms.sakai.devel/51415/51416 0\n",
    "\n",
    "    Does not start with From\n",
    "\n",
    "El programa escanea `content.sqlite` desde uno hasta el primer número de mensaje que aún no se ha arañado y comienza a arañar ese mensaje. Continúa arañando hasta que ha arañado el número deseado de mensajes o llega a una página que no parece ser un mensaje con el formato correcto.\n",
    "\n",
    "A veces a gmane.org le falta un mensaje. Quizás los administradores puedan eliminar mensajes o quizás se pierdan. Si su araña se detiene, y parece que ha encontrado un mensaje faltante, vaya al Administrador de SQLite y agregue una fila con la identificación faltante dejando todos los demás campos en blanco y reinicie `gmane.py`. Esto despegará el proceso de arrastre y permitirá que continúe. Estos mensajes vacíos serán ignorados en la siguiente fase del proceso.\n",
    "\n",
    "Una cosa buena es que una vez que haya revisado todos los mensajes y los tenga en `content.sqlite`, puede ejecutar `gmane.py` nuevamente para obtener nuevos mensajes a medida que se envían a la lista.\n",
    "\n",
    "Los datos de `content.sqlite` son bastante crudos, con un modelo de datos ineficiente y no están comprimidos. Esto es intencional ya que le permite mirar `content.sqlite` en el Administrador de SQLite para depurar problemas con el proceso de spidering. Sería una mala idea ejecutar consultas en esta base de datos, ya que serían bastante lentas.\n",
    "\n",
    "El segundo proceso es ejecutar el programa `gmodel.py`. Este programa lee los datos sin procesar de `content.sqlite` y produce una versión limpia y modelada de los datos en el archivo `index.sqlite`. Este archivo será mucho más pequeño (a menudo 10 veces más pequeño) que `content.sqlite` porque también comprime el encabezado y el texto del cuerpo.\n",
    "\n",
    "Cada vez que `gmodel.py` se ejecuta, elimina y reconstruye `index.sqlite`, lo que le permite ajustar sus parámetros y editar las tablas de mapeo en `content.sqlite` para modificar el proceso de limpieza de datos. Esta es una muestra de ejecución de `gmodel.py`. Imprime una línea cada vez que se procesan 250 mensajes de correo para que pueda ver algún progreso, ya que este programa puede ejecutarse durante un tiempo procesando casi un gigabyte de datos de correo.\n",
    "\n",
    "    Loaded allsenders 1588 and mapping 28 dns mapping 1\n",
    "    1 2005-12-08T23:34:30-06:00 ggolden22@mac.com\n",
    "    251 2005-12-22T10:03:20-08:00 tpamsler@ucdavis.edu\n",
    "    501 2006-01-12T11:17:34-05:00 lance@indiana.edu\n",
    "    751 2006-01-24T11:13:28-08:00 vrajgopalan@ucmerced.edu\n",
    "    ...\n",
    "\n",
    "El programa `gmodel.py` maneja una serie de tareas de limpieza de datos.\n",
    "\n",
    "Los nombres de dominio se truncan a dos niveles para .com, .org, .edu y .net. Otros nombres de dominio se truncan a tres niveles. Entonces si.umich.edu se convierte en umich.edu y caret.cam.ac.uk se convierte en cam.ac.uk. Las direcciones de correo electrónico también están obligadas a usar minúsculas, y algunas de las direcciones de @ gmane.org son las siguientes:\n",
    "\n",
    "    arwhyte-63aXycvo3TyHXe+LvDLADg@public.gmane.org\n",
    "    \n",
    "se convierten a la dirección real siempre que haya una dirección de correo electrónico real coincidente en otra parte del corpus de mensajes.\n",
    "\n",
    "En la base de datos `mapping.sqlite` hay dos tablas que le permiten asignar nombres de dominio y direcciones de correo electrónico individuales que cambian durante la vida útil de la lista de correo electrónico. Por ejemplo, Steve Githens utilizó las siguientes direcciones de correo electrónico mientras cambiaba de trabajo durante la vida de la lista de desarrolladores de Sakai:\n",
    "\n",
    "    s-githens@northwestern.edu\n",
    "    sgithens@cam.ac.uk\n",
    "    swgithen@mtu.edu\n",
    "\n",
    "Podemos añadir dos entradas a la tabla de asignación de `mapping.sqlite` por lo `gmodel.py` asignará los tres a una dirección:\n",
    "\n",
    "    s-githens@northwestern.edu ->  swgithen@mtu.edu\n",
    "    sgithens@cam.ac.uk -> swgithen@mtu.edu\n",
    "\n",
    "También puede realizar entradas similares en la tabla DNSMapping si hay varios nombres DNS que desea asignar a un solo DNS. La siguiente asignación se agregó a los datos de Sakai:\n",
    "\n",
    "    iupui.edu -> indiana.edu\n",
    "\n",
    "Así que todas las cuentas de los distintos campus de la Universidad de Indiana se rastrean juntas.\n",
    "\n",
    "Puede volver a ejecutar `gmodel.py` una y otra vez a medida que mira los datos, y agregar asignaciones para hacer que los datos sean más y más limpios. Cuando haya terminado, tendrá una versión bien indexada del correo electrónico en `index.sqlite`. Este es el archivo a utilizar para hacer análisis de datos. Con este archivo, el análisis de datos será realmente rápido.\n",
    "\n",
    "El primer análisis de datos más simple es determinar \"¿quién envió más correo?\" y \"¿qué organización envió más correo\"? Esto se hace usando `gbasic.py`:\n",
    "\n",
    "    How many to dump? 5\n",
    "    Loaded messages= 51330 subjects= 25033 senders= 1584\n",
    "\n",
    "    Top 5 Email list participants\n",
    "    steve.swinsburg@gmail.com 2657\n",
    "    azeckoski@unicon.net 1742\n",
    "    ieb@tfd.co.uk 1591\n",
    "    csev@umich.edu 1304\n",
    "    david.horwitz@uct.ac.za 1184\n",
    "\n",
    "    Top 5 Email list organizations\n",
    "    gmail.com 7339\n",
    "    umich.edu 6243\n",
    "    uct.ac.za 2451\n",
    "    indiana.edu 2258\n",
    "    unicon.net 2055\n",
    "\n",
    "Tenga en cuenta cuánto más rápido se ejecuta `gbasic.py` en comparación con `gmane.py` o incluso `gmodel.py`. Todos están trabajando en los mismos datos, pero `gbasic.py` está utilizando los datos comprimidos y normalizados en `index.sqlite`. Si tiene muchos datos para administrar, un proceso de varios pasos como el de esta aplicación puede demorar un poco más en desarrollarse, pero le ahorrará mucho tiempo cuando realmente comience a explorar y visualizar sus datos.\n",
    "\n",
    "Puede producir una visualización simple de la frecuencia de palabras en las líneas de asunto en el archivo `gword.py`:\n",
    "\n",
    "    Range of counts: 33229 129\n",
    "    Output written to gword.js\n",
    "\n",
    "Esto produce el archivo `gword.js` que puede visualizar usando `gword.htm` para producir una nube de palabras similar a la del comienzo de esta sección.\n",
    "\n",
    "Una segunda visualización es producida por `gline.py`. Calcula la participación del correo electrónico de las organizaciones a lo largo del tiempo.\n",
    "\n",
    "    Loaded messages= 51330 subjects= 25033 senders= 1584\n",
    "    Top 10 Oranizations\n",
    "    ['gmail.com', 'umich.edu', 'uct.ac.za', 'indiana.edu',\n",
    "    'unicon.net', 'tfd.co.uk', 'berkeley.edu', 'longsight.com',\n",
    "    'stanford.edu', 'ox.ac.uk']\n",
    "    Output written to gline.js\n",
    "\n",
    "Su salida se escribe en `gline.js` que se visualiza usando `gline.htm`.\n",
    "\n",
    "![Figura 16.4](./figures/mailorg.png)\n",
    "<cennter><i>Figura 16.4: Actividad del correo Sakai por organización</i></center>\n",
    "\n",
    "Esta es una aplicación relativamente compleja y sofisticada y tiene características para realizar una recuperación, limpieza y visualización de datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "| [Indice](indice.ipynb) | \n",
    "\n",
    "< [Capítulo 15 - Uso de bases de datos y SQL](cap15.ipynb) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
